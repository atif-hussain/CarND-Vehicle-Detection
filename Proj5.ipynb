{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# CarND-Term1 Project 5: Vehicle Detection (by Atif)\n",
    "\n",
    "Detect Vehicles on the road. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Import all libraries used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from scipy import misc\n",
    "from skimage.feature import hog \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle \n",
    "import os\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Extraction of features from a images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_features(img, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, color_range=(0, 256)) : \n",
    "\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        else: feature_image = np.copy(img)\n",
    "\n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = cv2.resize(feature_image,spatial_size).ravel()\n",
    "\n",
    "        # Apply color_hist() also with a color space option now\n",
    "        channel1_hist = np.histogram(feature_image[:,:,0], bins=hist_bins, range=color_range)\n",
    "        channel2_hist = np.histogram(feature_image[:,:,1], bins=hist_bins, range=color_range)\n",
    "        channel3_hist = np.histogram(feature_image[:,:,2], bins=hist_bins, range=color_range)\n",
    "        hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "        \n",
    "        # Compute the HOG features for input image \n",
    "        hog_features = []\n",
    "        for channel in range(feature_image.shape[2]):\n",
    "            hog_features.append(hog(feature_image[:, :, channel], orientations=9, pixels_per_cell=(8,8),\n",
    "                           cells_per_block=(2,2), transform_sqrt=True, \n",
    "                           visualise=False, feature_vector=True))\n",
    "        hog_features = np.ravel(hog_features)\n",
    "        \n",
    "        # Append the new feature vector to the features list and Return list of feature vectors\n",
    "        features = np.concatenate((spatial_features, hist_features, hog_features))\n",
    "        return features\n",
    "\n",
    "def extract_features_2(img, spatial_size=(32, 32),\n",
    "                        hist_bins=32, color_range=(0, 256)) : \n",
    "        rgb_features = extract_features(img, 'RGB', spatial_size, hist_bins, color_range)\n",
    "        hsv_features = extract_features(img, 'HSV', spatial_size, hist_bins, color_range)\n",
    "        return np.concatenate([rgb_features, hsv_features])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8792\n",
      "17760\n",
      "(17760, 16920)\n",
      "(17760,)\n"
     ]
    }
   ],
   "source": [
    "feature_set = []\n",
    "output=[]\n",
    "\n",
    "images = glob.glob('vehicles/*/*.png')\n",
    "for imname in images:\n",
    "        img = cv2.imread(imname)\n",
    "        a = extract_features_2(img)\n",
    "        feature_set.append(a)\n",
    "output = [1 for i in range(len(feature_set))]\n",
    "print(len(feature_set))\n",
    "\n",
    "images = glob.glob('non-vehicles/*/*.png')\n",
    "for imname in images :\n",
    "        img = cv2.imread(imname)\n",
    "        a = extract_features_2(img)\n",
    "        feature_set.append(a)\n",
    "output.extend([0 for i in range(len(feature_set)-len(output))])\n",
    "print(len(feature_set))\n",
    "\n",
    "outputY = np.array(output)\n",
    "dataX = np.array(feature_set)\n",
    "print(dataX.shape)\n",
    "print(outputY.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Use test inputs and create a linear-SVM model for classifying 64x64x3 images as having Car or Not-Car \n",
    "Compute linear SVM for classifying images. \n",
    "Load existing model file if exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(\"./SVM.sav\"):\n",
    "    svm = pickle.load(open(\"SVM.sav\",'rb'))\n",
    "\n",
    "else:\n",
    "    svm = SVC(kernel='linear')\n",
    "    train_data,test_data ,train_labels ,test_labels  = train_test_split(dataX,outputY,test_size = 0.3,random_state=3)\n",
    "    print(train_data.shape,test_labels.shape)\n",
    "    svm.fit(train_data,train_labels)\n",
    "    pred_labels = svm.predict(test_data)\n",
    "    pickle.dump(svm, open(\"SVM.sav\", 'wb'))\n",
    "    print(confusion_matrix(test_labels,pred_labels))\n",
    "    print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Apply the predicted model to classify car/not-car label for a given window in frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "i = 10\n",
    "def predict_car(image, window, trace=False):\n",
    "    global svm\n",
    "    global i\n",
    "    #x_range = window[1][0] - window[0][0]\n",
    "    #y_range = window[1][1] - window[0][1]\n",
    "    if trace and i>0:\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "    cropped_image = image[window[0][1]:window[1][1],window[0][0]:window[1][0],:]\n",
    "    if trace and i>0:\n",
    "        plt.imshow(cropped_image)\n",
    "        plt.show()\n",
    "    resized_image =  cv2.resize(cropped_image,(64,64))\n",
    "    if trace and i>0:\n",
    "        plt.imshow(resized_image)\n",
    "        plt.show()\n",
    "    test_data     = extract_features_2(resized_image)\n",
    "    pred_label = svm.predict(test_data) \n",
    "    if trace and i>0:\n",
    "        print(\"predicted \", pred_label)\n",
    "        i = i-1\n",
    "\n",
    "    return pred_label\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Slide fixed size windows across the image to detect presence of car "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            \n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Slide multiple sized windows within focus region of image (focus smaller for small window) to reduce search space, to detect presence of car. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def slide_variable_window(image,size_list):\n",
    "    windows=[]\n",
    "    for size in size_list:\n",
    "          windows.extend((slide_window(image,  x_start_stop=[image.shape[1]//5-size//2, image.shape[1]*4//5+size//2], \n",
    "                                    y_start_stop=[image.shape[0]*2//3-size//2, image.shape[0]*9//10+size//2], \n",
    "                                    xy_window=(size, size), xy_overlap=(0.6, 0.6))))\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Augment input image with detected cars regions \n",
    "1. Slide-window across the Input image \n",
    "2. Identify presence of cars in each window\n",
    "    * scale the window region, and extract features from it \n",
    "    * predict the label (car/no-car) for each window\n",
    "3. Draw all car containing windows on input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        #cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "        center = ((bbox[0][0]+bbox[1][0])//2, (bbox[0][1]+bbox[1][1])//2)\n",
    "        cv2.circle(imcopy, center, (bbox[1][0]-bbox[0][0])//2, (np.random.rand()*255,np.random.rand()*255,np.random.rand()*255), thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "    \n",
    "\n",
    "def augment (img): \n",
    "    global i\n",
    "    window_list = slide_variable_window(base,[256,160,96,64])\n",
    "    predicted_cars=[]\n",
    "    for window in window_list:\n",
    "      pred_label = predict_car(img, window)\n",
    "      if pred_label == 1:\n",
    "            predicted_cars.append(window)\n",
    "            predict_car(img, window, True)\n",
    "\n",
    "    augmented = draw_boxes(img, predicted_cars, color=(0, 0, 255), thick=6)         \n",
    "    return augmented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "video_in = VideoFileClip('project_video'+'.mp4') #.subclip(30,51)\n",
    "base = video_in.get_frame(47)\n",
    "\n",
    "window_img = augment(base)\n",
    "#print(predicted_cars)       \n",
    "plt.imshow(window_img)\n",
    "plt.show()\n",
    "\n",
    "video_out = video_in.subclip(30,41).fl_image(augment)  # NOTE: this function expects color images!!\n",
    "video_out.write_videofile('project_video'+'_augmented.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
